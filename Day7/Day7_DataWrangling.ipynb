{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You need to import a comma-separated values (CSV) file.\n",
    "\n",
    "#Solution\n",
    "#Use the pandas library’s read_csv to load a local or hosted CSV file:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL or path\n",
    "url = 'https://domain.com/data.csv'\n",
    "\n",
    "# Load dataset\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You need to import an Excel spreadsheet.\n",
    "\n",
    "#Solution\n",
    "#Use the pandas library’s read_excel to load an Excel spreadsheet:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to excel'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_excel(url, sheetname=0, header=1)\n",
    "\n",
    "# View the first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You need to load a JSON file for data preprocessing.\n",
    "\n",
    "#Solution\n",
    "#The pandas library provides read_json to convert a JSON file into a pandas object:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to json'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_json(url)\n",
    "\n",
    "# View the first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You need to load data from a database using the structured query language (SQL).\n",
    "\n",
    "#Solution\n",
    "#pandas’ read_sql_query allows us to make a SQL query to a database and load it: ---- SQLite\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a connection to the database\n",
    "database_connection = create_engine('sqlite:///sample.db')\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_sql_query('SELECT * FROM data', database_connection)\n",
    "\n",
    "# View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You want to create a new data frame.\n",
    "\n",
    "#Solution\n",
    "#pandas has many methods of creating a new DataFrame object. One easy method is to create an empty data frame using DataFrame and then define each column separately:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# Add columns\n",
    "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
    "dataframe['Age'] = [38, 25]\n",
    "dataframe['Driver'] = [True, False]\n",
    "\n",
    "# Show DataFrame\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You want to view some characteristics of a DataFrame.\n",
    "\n",
    "#Solution\n",
    "3One of the easiest things we can do after loading the data is view the first few rows using head:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path of the csv file'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Show two rows\n",
    "dataframe.head(2)\n",
    "\n",
    "# Show dimensions\n",
    "dataframe.shape\n",
    "\n",
    "# Show statistics\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You need to select individual data or slices of a DataFrame.\n",
    "\n",
    "#Solution\n",
    "#Use loc or iloc to select one or more rows or values:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to csv file'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Select first row\n",
    "dataframe.iloc[0]\n",
    "\n",
    "#selecting the second, third, and fourth rows:\n",
    "# Select three rows\n",
    "dataframe.iloc[1:4]\n",
    "\n",
    "# Select four rows\n",
    "dataframe.iloc[:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top two rows where column 'sex' is 'female'\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Multiple conditions \n",
    "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to replace values in a DataFrame.\n",
    "dataframe['Sex'].replace(\"female\", \"Woman\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace multiple values at the same time\n",
    "dataframe['Sex'].replace([\"female\", \"male\"], [\"Woman\", \"Man\"]).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You want to rename a column in a pandas DataFrame.\n",
    "\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class'}).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You want to find the min, max, sum, average, or count of a numeric column.\n",
    "\n",
    "#Solution\n",
    "#pandas comes with some built-in methods for commonly used descriptive statistics:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to csv file'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Calculate statistics\n",
    "print('Maximum:', dataframe['Age'].max())\n",
    "print('Minimum:', dataframe['Age'].min())\n",
    "print('Mean:', dataframe['Age'].mean())\n",
    "print('Sum:', dataframe['Age'].sum())\n",
    "print('Count:', dataframe['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem\n",
    "You want to select all unique values in a column.\n",
    "\n",
    "Solution\n",
    "Use unique to view an array of all unique values in a column:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to csv file'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Select unique values\n",
    "dataframe['Sex'].unique()\n",
    "\n",
    "# or use value_counts will display all unique values with the number of times each value appears:\n",
    "dataframe['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem\n",
    "#You want to select missing values in a DataFrame.\n",
    "\n",
    "#Solution\n",
    "#isnull and notnull return booleans indicating whether a value is missing:\n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'path to csv file'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "## Select missing values, show two rows\n",
    "dataframe[dataframe['Age'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to replace values with NaN\n",
    "dataframe['Sex'] = dataframe['Sex'].replace('male', NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize while lloading\n",
    "# Load data, set missing values\n",
    "dataframe = pd.read_csv(url, na_values=[np.nan, 'NONE', -999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete column\n",
    "dataframe.drop('Age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete multiple columns\n",
    "dataframe.drop(['Age', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column by index\n",
    "dataframe.drop(dataframe.columns[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rows by the values of the column 'Sex', calculate mean\n",
    "# of each group\n",
    "dataframe.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uppercase all values in name column\n",
    "dataframe['Name'].apply(uppercase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames by rows (UNION)\n",
    "pd.concat([dataframe_a, dataframe_b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join between two dataframes in a key\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id')\n",
    "\n",
    "#left outer join\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='left')\n",
    "\n",
    "#right outer join\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='right')\n",
    "\n",
    "#Note: https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transforming raw numerical data into features\n",
    "#Problem\n",
    "#You need to rescale the values of a numerical feature to be between two values.\n",
    "\n",
    "#Solution\n",
    "#Use scikit-learn’s MinMaxScaler to rescale a feature array:\n",
    "\n",
    "\n",
    "#Note: Many of the ML algorithms will assume all features are on the same scale, typically 0 to 1 or –1 to 1\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create feature\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "# Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale feature\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "# Show feature\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem\n",
    "#You want to transform a feature to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "#Solution\n",
    "#scikit-learn’s StandardScaler performs both transformations:\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Create feature\n",
    "x = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "              [500.5],\n",
    "              [600.6],\n",
    "              [9000.9]])\n",
    "\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "# Show feature\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1307bda143f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "#Problem\n",
    "#You have missing values in your data and want to predict their values. and fill\n",
    "\n",
    "#Solution\n",
    "#If you have a small amount of data, predict the missing values using k-nearest neighbors (KNN):\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Make a simulated feature matrix\n",
    "features = make_blobs(n_samples = 1000,\n",
    "                         n_features = 2,\n",
    "                         random_state = 1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "\n",
    "# Predict the missing values in the feature matrix\n",
    "features_knn_imputed = KNN(k=5, verbose=0).complete(standardized_features)\n",
    "\n",
    "# Compare true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
